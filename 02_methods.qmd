# Expert Opinion Methods

```{r load curated data, echo = F, include = F, eval = T }
extraction.location <- "Data\\Delphi round 1\\"
load(paste0(extraction.location,"curated.RData"))
```

Expert opinion on the value function and weighting for each indicator was elicited using the Delphi method.

## The Delphi method

The Delphi method is a well-established method designed to collect and distill expert knowledge and has a history of successful use in supporting conservation action where empirical evidence is insufficient and information is needed rapidly to inform decisions. It's transparency and repeatability also add to its appeal.

The Delphi method relies on using repeated surveys where participants are asked the same questions in at least two to three ‘rounds’ . Between rounds participants review and consider the answers given by all panel-members and can then revise their answers, increasing their reliability <!-- (Edwards et al., 2011) --> and identifying areas where agreements and disagreements in understanding occur. <!-- (Buckley, 1995; Kangas, Alho, Kolehmainen, & Mononen, 1998; Landeta, 2006). -->

## Ellicitation of expert opinion

Each participant either attended an introductory workshop to the process, or was taken through individually. A sub-section of participants were also involved in development the proposed methods to measure each indicator in the field. Answers were submitted into individual Excel spread sheets, with questions relating to:

-   Value functions describing how each indicator related to WEC, in typical conditions.
    -   These were entered as points representing potential indicator measurements and that potential measurement's corresponding relative value (on a 0-100 scale from low to high).
-   Weightings describing the relative importance of each indicator to WEC, in typical conditions (by which an indicator's value would be multiplied).
-   Certainty around value function and weighting estimates (subjective score 0-5), to aid participants in reviewing responses.
-   Comments or concerns relating to: situations where these "typical" responses might be inappropriate, the proposed method to measure indicators, and any other relevant information.

Participants were encouraged to keep a clear distinction between the quantitative responses provided (i.e. value functions and weightings under typical conditions) and exceptions to those typical relationships (that they highlighted in their comments).

Participants were instructed that noted exceptions would be analysed and, where appropriate, used to inform future development of the WEC measure to account for important nuance.

## Analysis Method

### Edits to responses

In some cases where deemed appropriate (e.g. where respondents had described a linear trend using few, widely spaced points), points were added to value functions by visual interpolation. Some points where also added by extrapolation where a maximum/minimum value was clearly implied, and corrections where made to clearly erroneous points following individual consultation with respondents.

## Scaling values and weights

Values and weights are all measured relative to each other. Some respondents did not use the full 0 to 100 range for all value functions and weights. Comparison between participants requires that they all use the same scale, and so all value functions where scaled from 0 to 100 and weightings were scaled so that the highest indicator weighting for each panelist was 100.

<button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#Scaling_info_vf" aria-expanded="false" aria-controls="collapseExample">

Toggle details of responses requiring scaling - value functions

</button>

</p>

::: {#Scaling_info_vf .collapse}
::: {.card .card-body}
**Value functions** scaled for:

`r paste0("<br>", which.scaled$vf)`
:::
:::

<button class="btn btn-primary" type="button" data-bs-toggle="collapse" data-bs-target="#Scaling_info_wts" aria-expanded="false" aria-controls="collapseExample">

Toggle details of responses requiring scaling - weights

</button>

</p>

::: {#Scaling_info_wts .collapse}
::: {.card .card-body}
**Weights** were scaled for:

`r paste0("<br>- ", which.scaled$wt)`
:::
:::

### Reviewing results between rounds

A copy of this report was circulated to respondents between rounds to allow respondents to investigate estimates provided by others, and their certainties.

Where appropriate value functions where plotted categorically (with box plots summarising the estimated value at each category), and continuously. Indicator relative weightings were presented on boxplots, including the mean and median estimates. Interactive hover-text displayed respondent name and their certainty in their estimate.
